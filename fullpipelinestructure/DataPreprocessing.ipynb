{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-08T17:19:31.755234Z",
     "start_time": "2024-10-08T17:19:30.683846Z"
    }
   },
   "source": [
    "from random import sample\n",
    "\n",
    "from URLS import IMDB_DATASET_URL\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(IMDB_DATASET_URL)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "147e2aacd02f6ab8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T17:19:33.193693Z",
     "start_time": "2024-10-08T17:19:33.177472Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "485b5720d906e8fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing Data",
   "id": "e4387a54937c0089"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T17:20:05.227094Z",
     "start_time": "2024-10-08T17:20:04.747597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load the SpaCy English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess_reviews(df):\n",
    "    def clean_text(text):\n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        \n",
    "        # Remove special characters and punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "        # Process the text using SpaCy\n",
    "        doc = nlp(text.lower())\n",
    "        \n",
    "        # Remove stopwords and lemmatize\n",
    "        tokens = [\n",
    "            token.lemma_ \n",
    "            for token in doc \n",
    "            if not token.is_stop and not token.is_punct\n",
    "        ]\n",
    "        \n",
    "        # Join tokens back to string\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    # Apply the cleaning function to the 'review' column\n",
    "    df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "    return df"
   ],
   "id": "e61c3cc412a27ba8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save preprocessed text",
   "id": "4f95e109654ac34e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T17:22:03.179362Z",
     "start_time": "2024-10-08T17:22:00.905918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample_df = df.sample(n=100, random_state=42)\n",
    "preprocessed_df = preprocess_reviews(sample_df)\n",
    "preprocessed_df.head()"
   ],
   "id": "5602822fc4f44bad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "33553  I really liked this Summerslam due to the look...  positive   \n",
       "9427   Not many television shows appeal to quite as m...  positive   \n",
       "199    The film quickly gets to a major chase scene w...  negative   \n",
       "12447  Jane Austen would definitely approve of this o...  positive   \n",
       "39489  Expectations were somewhat high for me when I ...  negative   \n",
       "\n",
       "                                          cleaned_review  \n",
       "33553  like summerslam look arena curtain look overal...  \n",
       "9427   television show appeal different kind fan like...  \n",
       "199    film quickly get major chase scene increase de...  \n",
       "12447  jane austen definitely approve onegwyneth palt...  \n",
       "39489  expectation somewhat high go movie think steve...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "      <td>like summerslam look arena curtain look overal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>television show appeal different kind fan like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>film quickly get major chase scene increase de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>jane austen definitely approve onegwyneth palt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>expectation somewhat high go movie think steve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Text Data Representation & Vectorize Model to pass on AI/ML \n",
    "\n",
    "## There are different ways to represent text data\n",
    "### 1 -> One-Hot Encoding\n",
    " The way it work is finding unique words and create vectors of 0s and 1s where 1 represents particular word and 0 nothing\n",
    " \n",
    "#### Problems\n",
    "1. Out Of Vocabulary issues\n",
    "2. Don't understand semantic meaning\n",
    "3. Computationally costly\n",
    "4. A lot of theres which is not used and just make you to use more computation \n",
    "### 2 -> Bag Of Words\n",
    "First finds unique words then calculates frequencies of each word, which is good suited for classification tasks, for example\n",
    "classifying whether sentence is negative or positive, based on frequency the words used in the sentence you'll find answer\n",
    "\n",
    "#### Problems are same as One-hot encoding have but it works better and use less 0s\n",
    "### 3 -> TF-IDF\n",
    "TF-IDF finds important words by measuring their frequency in a document (TF) and how uncommon they are across all documents (IDF), highlighting unique terms.\n",
    "\n",
    "Formula:\n",
    "TF-IDF = TF * log(N / DF)\n",
    "\n",
    "Where:\n",
    "\n",
    "    TF = term frequency\n",
    "    N = total number of documents\n",
    "    DF = number of documents containing the term\n",
    "\n",
    "### 4 -> N-Grams \n",
    "Choosing N which represents the number of words be used to count the number of words. For example if N=3 You will you 3 words.\n",
    "\n",
    "### 4-> Word2Vec\n",
    "Word2Vec transforms words into continuous vector spaces through neural networks, capturing semantic relationships.\n",
    "\n",
    "    Input Layer: Takes one-hot encoded words.\n",
    "    Projection Layer: Learns weights (embeddings) via skip-gram or CBOW.\n",
    "    Output Layer: Predicts context words from target words.\n",
    "    Training: Utilizes gradient descent and backpropagation to optimize embeddings.\n",
    "\n",
    "Final: Generates dense word vectors reflecting word meanings and relationships.\n",
    "\n",
    "\n",
    "  ![word2vec](../images/word2vecsteps.png)\n",
    "\n",
    "\n",
    "### 5-> Transformers\n",
    "\n",
    "Transformers are deep learning models designed for sequential data, using self-attention mechanisms to weigh the importance of different input parts. They process data in parallel, allowing for efficient handling of long-range dependencies. This architecture underlies many state-of-the-art natural language processing tasks, such as translation and text generation.\n",
    "\n",
    "# Now All is left is to use just ML model and get results on movie data \n"
   ],
   "id": "27c58d360c871604"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "48ed561c5bc13c89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "36749dfa03d4c92d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d5a0f6fc2a90a080"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
